// Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.
//
// Redistribution and use in source and binary forms, with or without
// modification, are permitted provided that the following conditions
// are met:
//  * Redistributions of source code must retain the above copyright
//    notice, this list of conditions and the following disclaimer.
//  * Redistributions in binary form must reproduce the above copyright
//    notice, this list of conditions and the following disclaimer in the
//    documentation and/or other materials provided with the distribution.
//  * Neither the name of NVIDIA CORPORATION nor the names of its
//    contributors may be used to endorse or promote products derived
//    from this software without specific prior written permission.
//
// THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS ``AS IS'' AND ANY
// EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
// IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR
// PURPOSE ARE DISCLAIMED.  IN NO EVENT SHALL THE COPYRIGHT OWNER OR
// CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL,
// EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO,
// PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR
// PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY
// OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
// (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
// OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

syntax = "proto3";

package inference;

import "model_config.proto";

service GRPCInferenceService
{
  rpc ServerLive(ServerLiveRequest) returns (ServerLiveResponse) {}
  rpc ServerReady(ServerReadyRequest) returns (ServerReadyResponse) {}
  rpc ModelReady(ModelReadyRequest) returns (ModelReadyResponse) {}
  rpc ServerMetadata(ServerMetadataRequest) returns (ServerMetadataResponse) {}
  rpc ModelMetadata(ModelMetadataRequest) returns (ModelMetadataResponse) {}
  rpc ModelInfer(ModelInferRequest) returns (ModelInferResponse) {}
  rpc ModelStreamInfer(stream ModelInferRequest) returns (stream ModelStreamInferResponse) {}
  rpc ModelConfig(ModelConfigRequest) returns (ModelConfigResponse) {}
  rpc ModelStatistics(ModelStatisticsRequest) returns (ModelStatisticsResponse) {}
  rpc RepositoryIndex(RepositoryIndexRequest) returns (RepositoryIndexResponse) {}
  rpc RepositoryModelLoad(RepositoryModelLoadRequest) returns (RepositoryModelLoadResponse) {}
  rpc RepositoryModelUnload(RepositoryModelUnloadRequest) returns (RepositoryModelUnloadResponse) {}
  rpc SystemSharedMemoryStatus(SystemSharedMemoryStatusRequest) returns (SystemSharedMemoryStatusResponse) {}
  rpc SystemSharedMemoryRegister(SystemSharedMemoryRegisterRequest) returns (SystemSharedMemoryRegisterResponse) {}
  rpc SystemSharedMemoryUnregister(SystemSharedMemoryUnregisterRequest) returns (SystemSharedMemoryUnregisterResponse) {}
  rpc CudaSharedMemoryStatus(CudaSharedMemoryStatusRequest) returns (CudaSharedMemoryStatusResponse) {}
  rpc CudaSharedMemoryRegister(CudaSharedMemoryRegisterRequest) returns (CudaSharedMemoryRegisterResponse) {}
  rpc CudaSharedMemoryUnregister(CudaSharedMemoryUnregisterRequest) returns (CudaSharedMemoryUnregisterResponse) {}
}

message ServerLiveRequest {}

message ServerLiveResponse {
  bool live = 1;
}

message ServerReadyRequest {}

message ServerReadyResponse {
  bool ready = 1;
}

message ModelReadyRequest {
  string name = 1;
  string version = 2;
}

message ModelReadyResponse {
  bool ready = 1;
}

message ServerMetadataRequest {}

message ServerMetadataResponse {
  string name = 1;
  string version = 2;
  repeated string extensions = 3;
}

message ModelMetadataRequest {
  string name = 1;
  string version = 2;
}

message ModelMetadataResponse {
  message TensorMetadata {
    string name = 1;
    string datatype = 2;
    repeated int64 shape = 3;
  }
  string name = 1;
  repeated string versions = 2;
  string platform = 3;
  repeated TensorMetadata inputs = 4;
  repeated TensorMetadata outputs = 5;
}

message InferParameter {
  oneof parameter_choice {
    bool bool_param = 1;
    int64 int64_param = 2;
    string string_param = 3;
  }
}

message InferTensorContents {
  repeated bool bool_contents = 1;
  repeated int32 int_contents = 2;
  repeated int64 int64_contents = 3;
  repeated uint32 uint_contents = 4;
  repeated uint64 uint64_contents = 5;
  repeated float fp32_contents = 6;
  repeated double fp64_contents = 7;
  repeated bytes byte_contents = 8;
}

message ModelInferRequest {
  message InferInputTensor {
    string name = 1;
    string datatype = 2;
    repeated int64 shape = 3;
    map<string, InferParameter> parameters = 4;
    InferTensorContents contents = 5;
  }
  message InferRequestedOutputTensor {
    string name = 1;
    map<string, InferParameter> parameters = 2;
  }
  string model_name = 1;
  string model_version = 2;
  string id = 3;
  map<string, InferParameter> parameters = 4;
  repeated InferInputTensor inputs = 5;
  repeated InferRequestedOutputTensor outputs = 6;
  repeated bytes raw_input_contents = 7;
}

message ModelInferResponse {
  message InferOutputTensor {
    string name = 1;
    string datatype = 2;
    repeated int64 shape = 3;
    map<string, InferParameter> parameters = 4;
    InferTensorContents contents = 5;
  }
  string model_name = 1;
  string model_version = 2;
  string id = 3;
  map<string, InferParameter> parameters = 4;
  repeated InferOutputTensor outputs = 5;
  repeated bytes raw_output_contents = 6;
}

message ModelStreamInferResponse {
  string error_message = 1;
  ModelInferResponse infer_response = 2;
}

message ModelConfigRequest {
  string name = 1;
  string version = 2;
}

message ModelConfigResponse {
  ModelConfig config = 1;
}

message ModelStatisticsRequest {
  string name = 1;
  string version = 2;
}

message StatisticDuration {
  uint64 count = 1;
  uint64 ns = 2;
}

message InferStatistics {
  StatisticDuration success = 1;
  StatisticDuration fail = 2;
  StatisticDuration queue = 3;
  StatisticDuration compute_input = 4;
  StatisticDuration compute_infer = 5;
  StatisticDuration compute_output = 6;
}

message InferBatchStatistics {
  uint64 batch_size = 1;
  StatisticDuration compute_input = 2;
  StatisticDuration compute_infer = 3;
  StatisticDuration compute_output = 4;
}

message ModelStatistics {
  string name = 1;
  string version = 2;
  uint64 last_inference = 3;
  uint64 inference_count = 4;
  uint64 execution_count = 5;
  InferStatistics inference_stats = 6;
  repeated InferBatchStatistics batch_stats = 7;
}

message ModelStatisticsResponse {
  repeated ModelStatistics model_stats = 1;
}

message ModelRepositoryParameter {
  oneof parameter_choice {
    bool bool_param = 1;
    int64 int64_param = 2;
    string string_param = 3;
  }
}

message RepositoryIndexRequest {
  string repository_name = 1;
  bool ready = 2;
}

message RepositoryIndexResponse {
  message ModelIndex {
    string name = 1;
    string version = 2;
    string state = 3;
    string reason = 4;
  }
  repeated ModelIndex models = 1;
}

message RepositoryModelLoadRequest {
  string repository_name = 1;
  string model_name = 2;
}

message RepositoryModelLoadResponse {}

message RepositoryModelUnloadRequest {
  string repository_name = 1;
  string model_name = 2;
  map<string, ModelRepositoryParameter> parameters = 3;
}

message RepositoryModelUnloadResponse {}

message SystemSharedMemoryStatusRequest {
  string name = 1;
}

message SystemSharedMemoryStatusResponse {
  message RegionStatus {
    string name = 1;
    string key = 2;
    uint64 offset = 3;
    uint64 byte_size = 4;
  }
  map<string, RegionStatus> regions = 1;
}

message SystemSharedMemoryRegisterRequest {
  string name = 1;
  string key = 2;
  uint64 offset = 3;
  uint64 byte_size = 4;
}

message SystemSharedMemoryRegisterResponse {}

message SystemSharedMemoryUnregisterRequest {
  string name = 1;
}

message SystemSharedMemoryUnregisterResponse {}

message CudaSharedMemoryStatusRequest {
  string name = 1;
}

message CudaSharedMemoryStatusResponse {
  message RegionStatus {
    string name = 1;
    uint64 device_id = 2;
    uint64 byte_size = 3;
  }
  map<string, RegionStatus> regions = 1;
}

message CudaSharedMemoryRegisterRequest {
  string name = 1;
  bytes raw_handle = 2;
  int64 device_id = 3;
  uint64 byte_size = 4;
}

message CudaSharedMemoryRegisterResponse {}

message CudaSharedMemoryUnregisterRequest {
  string name = 1;
}

message CudaSharedMemoryUnregisterResponse {}
